# embedding_generator.py
import logging
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
import numpy as np

logger = logging.getLogger(__name__)

class EmbeddingGenerator:
    """Táº¡o vector embeddings tá»« vÄƒn báº£n"""
    def __init__(self, model_name: str):
        try:
            logger.info(f"ðŸ”„ Äang táº£i embedding model: {model_name}")
            self.model = SentenceTransformer(model_name)
            self.model_name = model_name
            self.vector_dimension = self.model.get_sentence_embedding_dimension()
            logger.info(f"âœ… ÄÃ£ táº£i model '{model_name}' thÃ nh cÃ´ng. Dimension: {self.vector_dimension}")
        except Exception as e:
            logger.warning(f"âš ï¸ KhÃ´ng thá»ƒ táº£i model {model_name}. Lá»—i: {e}. Äang chuyá»ƒn sang model dá»± phÃ²ng.")
            fallback_model = "sentence-transformers/all-MiniLM-L6-v2"
            self.model = SentenceTransformer(fallback_model)
            self.model_name = fallback_model
            self.vector_dimension = self.model.get_sentence_embedding_dimension()
            logger.info(f"âœ… ÄÃ£ táº£i model dá»± phÃ²ng: {fallback_model}")

    def create_embeddings(self, texts: List[str]) -> List[List[float]]:
        if not texts: return []
        try:
            logger.info(f"ðŸ”„ Äang táº¡o embeddings cho {len(texts)} Ä‘oáº¡n vÄƒn...")
            embeddings = self.model.encode(texts, show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True)
            embeddings_list = embeddings.tolist()
            logger.info(f"âœ… ÄÃ£ táº¡o {len(embeddings_list)} embeddings")
            return embeddings_list
        except Exception as e:
            logger.error(f"âŒ Lá»—i khi táº¡o embeddings: {e}")
            return []

    def get_model_info(self) -> Dict[str, Any]:
        return {
            'model_name': self.model_name,
            'vector_dimension': self.vector_dimension
        }